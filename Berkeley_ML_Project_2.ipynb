{"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport datatable as dt","metadata":{"cell_id":"18f9a10784b944219113f11bd02741d7","source_hash":"8f139b24","execution_start":1666650554307,"execution_millis":2101,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'datatable'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn [1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatatable\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mdt\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datatable'"]}],"execution_count":1},{"cell_type":"code","source":"snp_orig_dt = dt.fread(\"869_NoCal_CR0.99.tagSNPs_BigLD0.70.txt\")\ncloud_dens_orig = pd.read_csv(\"cloud_dens_yearAvg\", sep=\"\\t\", header=None)\ntmin_orig = pd.read_csv(\"tmin_yearAvg\", sep=\"\\t\", header=None)","metadata":{"cell_id":"2714f7e83a124254b12d7304d32fe266","deepnote_cell_type":"code"},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"We randomly selected 10,000 features from the dataset to use in our models. Running our models on the full set of features would be computationally infeasible for our machines. 10,000 features was a good number, because we were to able to include a large number of features without the code taking too long to run.    ","metadata":{"tags":[],"cell_id":"96ecb855669c4dffb708cf2b760e0da9","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"import random\n\nk = 10000\nsnp_sample = dt.Frame()\nsnp_sample.cbind([snp_orig_dt[col] for col in random.sample(snp_orig_dt.names[6:], k)])\n\nsnp_sample = snp_sample.to_pandas()","metadata":{"cell_id":"321e051ab04a4b5ca2bcd8c5ac5266c7","deepnote_cell_type":"code"},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"To handle the NAs, rather than throwing out all of the NAs, we apply a KNN classification by taking the 10 closest datapoints in the high dimensional space and taking the most common value. We argue that in doing this rather than taking the mean of the 10 closest data points, we can output a valid value, but more specifically, similar looking variants would have mutated in a similar fashion.","metadata":{"tags":[],"cell_id":"7e369ce6f98644f9be9e17f02f56398c","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"display(snp_sample.iloc[:, 1:10].describe())\ndisplay(tmin_orig[2].describe())\ndisplay(cloud_dens_orig[2].describe())","metadata":{"cell_id":"53d84a845bfc4ceb8448c468dbb5c6a2","deepnote_cell_type":"code"},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Chr06_23493718_A</th>\n      <th>Chr01_28502495_T</th>\n      <th>Chr10_8941925_C</th>\n      <th>Chr16_1372888_G</th>\n      <th>Chr16_452183_T</th>\n      <th>Chr06_20637860_A</th>\n      <th>Chr01_7473042_G</th>\n      <th>Chr09_8224355_A</th>\n      <th>Chr10_8210298_C</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>861.000000</td>\n      <td>869.000000</td>\n      <td>869.000000</td>\n      <td>868.000000</td>\n      <td>869.000000</td>\n      <td>868.000000</td>\n      <td>869.000000</td>\n      <td>869.000000</td>\n      <td>869.00000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>1.844367</td>\n      <td>1.871116</td>\n      <td>1.661680</td>\n      <td>1.841014</td>\n      <td>1.355581</td>\n      <td>1.228111</td>\n      <td>1.591484</td>\n      <td>1.844649</td>\n      <td>1.89298</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.393472</td>\n      <td>0.352027</td>\n      <td>0.556211</td>\n      <td>0.399047</td>\n      <td>0.657398</td>\n      <td>0.691716</td>\n      <td>0.557704</td>\n      <td>0.374946</td>\n      <td>0.33091</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>2.00000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.00000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.00000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.00000</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"       Chr06_23493718_A  Chr01_28502495_T  Chr10_8941925_C  Chr16_1372888_G  \\\ncount        861.000000        869.000000       869.000000       868.000000   \nmean           1.844367          1.871116         1.661680         1.841014   \nstd            0.393472          0.352027         0.556211         0.399047   \nmin            0.000000          0.000000         0.000000         0.000000   \n25%            2.000000          2.000000         1.000000         2.000000   \n50%            2.000000          2.000000         2.000000         2.000000   \n75%            2.000000          2.000000         2.000000         2.000000   \nmax            2.000000          2.000000         2.000000         2.000000   \n\n       Chr16_452183_T  Chr06_20637860_A  Chr01_7473042_G  Chr09_8224355_A  \\\ncount      869.000000        868.000000       869.000000       869.000000   \nmean         1.355581          1.228111         1.591484         1.844649   \nstd          0.657398          0.691716         0.557704         0.374946   \nmin          0.000000          0.000000         0.000000         0.000000   \n25%          1.000000          1.000000         1.000000         2.000000   \n50%          1.000000          1.000000         2.000000         2.000000   \n75%          2.000000          2.000000         2.000000         2.000000   \nmax          2.000000          2.000000         2.000000         2.000000   \n\n       Chr10_8210298_C  \ncount        869.00000  \nmean           1.89298  \nstd            0.33091  \nmin            0.00000  \n25%            2.00000  \n50%            2.00000  \n75%            2.00000  \nmax            2.00000  "},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"count    787.000000\nmean       0.286143\nstd        0.384057\nmin       -1.540761\n25%        0.134706\n50%        0.382787\n75%        0.511545\nmax        1.454448\nName: 2, dtype: float64"},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"count    8.690000e+02\nmean     2.759588e-15\nstd      1.000000e+00\nmin     -2.186202e+00\n25%     -8.531242e-01\n50%     -2.505856e-02\n75%      6.202628e-01\nmax      4.603463e+00\nName: 2, dtype: float64"},"metadata":{},"output_type":"display_data"}],"execution_count":22},{"cell_type":"markdown","source":"The output of the code below show that the maximum number of NaNs in a single column is very small considering we have a total of more than 800 samples, so we did not remove any columns based on their number of NaNs. Also, the maximum number of NaNs for a single sample is lower than 10% of the number of features, so we also decided to keep all samples. ","metadata":{"tags":[],"cell_id":"18d5949111f046f1b65896922cebd127","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"# NAs per column\nna_col = snp_sample.isna().sum()\ndisplay(na_col.describe())\n\n# NAs per row\nna_row = snp_sample.T.isna().sum()\ndisplay(na_row.describe())\n\n# NAs in temperature data\ndisplay(tmin_orig[2].isna().sum())\n\n# NAs in cloud density data\ndisplay(cloud_dens_orig[2].isna().sum())","metadata":{"cell_id":"5c843c01a42e4056ab041d40f167d2e4","deepnote_cell_type":"code"},"outputs":[{"data":{"text/plain":"count    1000.000000\nmean        1.541000\nstd         2.132338\nmin         0.000000\n25%         0.000000\n50%         1.000000\n75%         2.000000\nmax         8.000000\ndtype: float64"},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":"count    869.000000\nmean       1.773303\nstd        4.567510\nmin        0.000000\n25%        0.000000\n50%        1.000000\n75%        2.000000\nmax       65.000000\ndtype: float64"},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":"82\n0\n"}],"execution_count":23},{"cell_type":"markdown","source":"## Running the IRF to the naive RF","metadata":{"tags":[],"cell_id":"387e4d5cbedb471f8aaacf8c0b2ca973","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom irf.ensemble import wrf_reg\nfrom irf.utils import visualize_impurity_decrease, get_prevalent_interactions\nfrom sklearn.impute import KNNImputer\nimport matplotlib.pyplot as plt\nimport itertools\n\ndef get_interactions(X, y):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n    \n    # Imputing beforehand technically means we will be polluting our test data with validation data\n    # when doing CV, but it saves a lot on computation. As long as we don't use the final test data, \n    # we should be fine.\n    imputer = KNNImputer(n_neighbors=10)\n    X_train = imputer.fit_transform(X_train)\n    X_test = imputer.fit_transform(X_test)\n    \n    best_params = run_rf_cv(X_train, X_test, y_train, y_test)\n    \n    # Reusing best parameters from RF instead of doing CV again because IRF is too computationally expensive.\n    irf = wrf_reg(**best_params)\n    \n    print(\"Fitting IRF...\")\n    irf.fit(X_train, y_train, keep_record=False)\n\n    print(f\"R2 score: {irf.score(X_test, y_test)}\")\n    \n    visualize_interactions(irf)\n    \n\ndef run_rf_cv(X_train, X_test, y_train, y_test):\n    rf = RandomForestRegressor()\n    params = {'n_estimators': [100, 400, 800, 1600],\n              'max_features': ['sqrt', 'log2']}\n\n    # Only 3-fold due to low number of samples\n    clf = GridSearchCV(rf, params, verbose=3, cv=3)\n    \n    print(\"Running CV...\")\n    clf.fit(X_train, y_train)\n    \n    print(f\"Best parameters: {clf.best_params_}\")\n    print(f\"R2 score: {clf.best_estimator_.score(X_test, y_test)}\")\n    \n    return clf.best_params_\n\n\ndef visualize_interactions(irf):\n    visualize_impurity_decrease(irf, yscale='log', xscale=\"linear\")\n    \n    IMPURITY_DECREASE_THRESHOLD = 0.015\n    prevalence = get_prevalent_interactions(irf, impurity_decrease_threshold=IMPURITY_DECREASE_THRESHOLD)\n    \n    best_genes = list(sorted(filter(lambda x: len(x[0]) == 1, prevalence.items()), key=lambda x: -x[1]))\n    best_pair = max(filter(lambda x: len(x[0]) == 2, prevalence.items()), key=lambda x: x[1])\n\n    plt.rcParams['figure.figsize'] = [10, 20]\n    fig, axs = plt.subplots(4, 1)\n\n    for i, ax in enumerate(axs.reshape(-1)):\n        ax.set_title(f\"{snp_sample.columns[best_genes[i][0][0]]} (Prevalence: {best_genes[i][1]:.4f})\")\n        ax.boxplot([y[snp_sample.iloc[:, best_genes[1][0][0]] == i] for i in (0, 1, 2)], vert=True)\n\n    plt.tight_layout()\n    plt.show()\n\n    best_pair_names = (snp_sample.columns[best_pair[0][0]], snp_sample.columns[best_pair[0][1]])\n    fig, ax = plt.subplots()\n    ax.set_title(f\"Best pair: {best_pair_names} (Prevalence: {best_pair[1]:.4f})\")\n # Subgroup of variants. \n    combos = list(itertools.product((0, 1, 2), (0, 1, 2)))\n    ax.boxplot([y[(snp_sample.iloc[:, best_pair[0][0]] == i) & (snp_sample.iloc[:, best_pair[0][1]] == j)] for i, j in combos])\n\n    ax.set_xticklabels(combos)\n    plt.show()","metadata":{"cell_id":"b5cf5e69ea254d819cf9d6a1e918d95a","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We note that when comparing the results of the IRF and the naive RF, the IRF performs better to the naive RF.","metadata":{"tags":[],"cell_id":"daee2349bc414e4f940189cf70b4266b","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"When looking at the box plots on the x-axis, the number indicates the number of mutations for each variant. ","metadata":{"tags":[],"cell_id":"114eaf28-3173-4455-bcd9-666c2fb184d8","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"markdown","source":"It can be seen in the plots that for the single variants with most importance for temperature, having one mutations makes a big difference, but one and two mutations lead to somewhat similar results. ","metadata":{"tags":[],"cell_id":"380705abfad34a3fa4ec2182bbd1504a","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-p"}},{"cell_type":"code","source":"X_temp = snp_sample[~tmin_orig[2].isna()]\ny_temp = tmin_orig[2][~tmin_orig[2].isna()]\n\nget_interactions(X_temp, y_temp)","metadata":{"cell_id":"cd9e1a504d4043c2bf78e01147c12112","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_cloud = snp_sample\ny_cloud = cloud_dens_orig[2]\n\nget_interactions(X_cloud, y_cloud)","metadata":{"cell_id":"5cd63c0b12284e4085c6c0eed22ba75f","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=dc19fcf8-fcbc-4029-b9cc-903eb0e7b73d' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"name":"python","version":"3.9.12","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"},"deepnote_notebook_id":"61cb336869c646b78e4cdd0c49d968c3","deepnote_execution_queue":[]}}