{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import psycopg2 as psycopg2\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTid = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "testfile = Path(\"../Data/test.tsv\")\n",
    "trainfile = Path(\"../Data/train.tsv\")\n",
    "vaildfile = Path(\"../Data/valid.tsv\")\n",
    "# Code for reading the csv file and separating.\n",
    "data = []\n",
    "i = 0\n",
    "breakpoint = 100\n",
    "chunksize = 100\n",
    "totalRow = breakpoint * chunksize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to a pandas dataframe.\n",
    "dfTest = pd.read_table(testfile)\n",
    "dfTrain = pd.read_table(trainfile)\n",
    "dfValid = pd.read_table(vaildfile)\n",
    "\n",
    " \n",
    "# Labeling the columns   \n",
    "dfTest.columns = ['Id' ,'Label','Stament', 'Subject', 'Speaker', 'Job Title', 'State Info', 'Party', 'Brealy Truth', 'False Counts', 'Half Truth', 'Mostly Truth', 'Pants on Fire', 'Context']\n",
    "dfTrain.columns = ['Id' ,'Label','Stament', 'Subject', 'Speaker', 'Job Title', 'State Info', 'Party', 'Brealy Truth', 'False Counts', 'Half Truth', 'Mostly Truth', 'Pants on Fire', 'Context']\n",
    "dfValid.columns = ['Id' ,'Label','Stament', 'Subject', 'Speaker', 'Job Title', 'State Info', 'Party', 'Brealy Truth', 'False Counts', 'Half Truth', 'Mostly Truth', 'Pants on Fire', 'Context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1266, 14)\n",
      "(10239, 14)\n",
      "(1283, 14)\n",
      "(12788, 14) Empty DataFrame\n",
      "Columns: [Id, Label, Stament, Subject, Speaker, Job Title, State Info, Party, Brealy Truth, False Counts, Half Truth, Mostly Truth, Pants on Fire, Context]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Checking shapes \n",
    "print(dfTest.shape)\n",
    "print(dfTrain.shape)\n",
    "print(dfValid.shape)\n",
    "\n",
    "# Merging the dataframes\n",
    "df = pd.concat([dfTest,dfTrain,dfValid])\n",
    "print (df.shape,df.head(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sorting our y variables into FAKE or REAL\n",
    "df[\"Label\"] = np.where(df[\"Label\"] == \"barely-true\", \"REAL\", df[\"Label\"])\n",
    "df[\"Label\"] = np.where(df[\"Label\"] == \"true\", \"REAL\", df[\"Label\"])\n",
    "df['Label'] = np.where(df['Label'] == \"mostly-true\", \"REAL\", df[\"Label\"])\n",
    "\n",
    "df[\"Label\"] = np.where(df[\"Label\"] == \"half-true\", \"FAKE\", df[\"Label\"])\n",
    "df[\"Label\"] = np.where(df[\"Label\"] == \"mostly-false\", \"FAKE\", df[\"Label\"])\n",
    "df[\"Label\"] = np.where(df[\"Label\"] == \"false\", \"FAKE\", df[\"Label\"])\n",
    "df[\"Label\"] = np.where(df[\"Label\"] == \"pants-fire\", \"FAKE\", df[\"Label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12788, 2)\n",
      "Diller   Label                                            Stament\n",
      "0  FAKE  Wisconsin is on pace to double the number of l...\n",
      "1  FAKE  Says John McCain has done nothing to help the ...\n"
     ]
    }
   ],
   "source": [
    "baseline = df.iloc[:,1:3]\n",
    "print(baseline.shape)\n",
    "print (\"Diller\", baseline.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Speaker\n",
      "0  katrina-shankland\n",
      "1       donald-trump\n"
     ]
    }
   ],
   "source": [
    "df2 = df.iloc[:,4:5]\n",
    "print(df2.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Label                                            Stament            Speaker\n",
      "0  FAKE  Wisconsin is on pace to double the number of l...  katrina-shankland\n",
      "1  FAKE  Says John McCain has done nothing to help the ...       donald-trump\n"
     ]
    }
   ],
   "source": [
    "frame = [baseline, df2]\n",
    "baselineExtended = pd.concat(frame,  axis=1, join='inner') \n",
    "print (baselineExtended.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()   \n",
    "words = stopwords.words(\"english\")\n",
    "Data_transformed = baselineExtended['Stament'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a vectorized array with integers indicating frequency of words.\n",
    "vectorize = CountVectorizer(max_features=200,ngram_range=(1,3))\n",
    "x = vectorize.fit_transform(Data_transformed).toarray()\n",
    "y = np.array(df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of samples in the Train Dataset : 10230\n",
      "Total number of samples in the Test Dataset : 2558\n"
     ]
    }
   ],
   "source": [
    "# Creating a test split of 80/20.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=34)\n",
    "print('\\nTotal number of samples in the Train Dataset :',xtrain.shape[0])\n",
    "print('Total number of samples in the Test Dataset :',xtest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy score for Multinomial Naive Bayes : 0.5723221266614542\n",
      "Confusion Metrics for Multinomial Naive Bayes : \n",
      "\n",
      " [[584 642]\n",
      " [452 880]] \n",
      "\n",
      "\n",
      "Classification Report for Multinomial Naive Bayes :\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.56      0.48      0.52      1226\n",
      "        REAL       0.58      0.66      0.62      1332\n",
      "\n",
      "    accuracy                           0.57      2558\n",
      "   macro avg       0.57      0.57      0.57      2558\n",
      "weighted avg       0.57      0.57      0.57      2558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Second baseline model using multinomial naive bayes.\n",
    "mulNB = MultinomialNB().fit(xtrain, ytrain)\n",
    "print('\\nAccuracy score for Multinomial Naive Bayes :',mulNB.score(xtest,ytest))\n",
    "\n",
    "ypred_mul = mulNB.predict(xtest)\n",
    "\n",
    "print('Confusion Metrics for Multinomial Naive Bayes : \\n\\n',confusion_matrix(ytest, ypred_mul),'\\n\\n')\n",
    "print('Classification Report for Multinomial Naive Bayes :\\n\\n',classification_report(ytest,ypred_mul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy for Logistic regression: 56.2549 %\n",
      "Confusion Metrics for Logistic regression:\n",
      "\n",
      " [[577 649]\n",
      " [470 862]]\n",
      "Classification Report for Multinomial Naive Bayes :\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.55      0.47      0.51      1226\n",
      "        REAL       0.57      0.65      0.61      1332\n",
      "\n",
      "    accuracy                           0.56      2558\n",
      "   macro avg       0.56      0.56      0.56      2558\n",
      "weighted avg       0.56      0.56      0.56      2558\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Third baseline model using Logistic regression.\n",
    "scaler = StandardScaler()\n",
    "lr = LogisticRegression(max_iter = 600)\n",
    "log_model = Pipeline([('standardize', scaler),\n",
    "                    ('log_reg', lr)])\n",
    "\n",
    "log_model.fit(xtrain, ytrain)\n",
    "\n",
    "ypred_log = log_model.predict(xtest)\n",
    "test_accuracy = accuracy_score(ytest, ypred_log)*100\n",
    "\n",
    "print('Testing accuracy for Logistic regression: %.4f %%' % test_accuracy) \n",
    "print('Confusion Metrics for Logistic regression:\\n\\n', confusion_matrix(ytest, ypred_log))\n",
    "print('Classification Report for Multinomial Naive Bayes :\\n\\n',classification_report(ytest,ypred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1255009174346924\n",
      "Tid i min: 0.052091681957244874\n"
     ]
    }
   ],
   "source": [
    "slutTid = time.time()\n",
    "kage2 = slutTid-startTid\n",
    "print(kage2)\n",
    "print(\"Tid i min:\" ,kage2/60)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "425c1cb9f96b02dd326489ac6b96e3042bda6ec4abf5f4b3f4fc167f5a6a6fe0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
