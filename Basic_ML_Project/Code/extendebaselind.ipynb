{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and more "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import psycopg2 as psycopg2\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retive Data for Test and Training. The data is put into two sets at present "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTid = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def getDataSets(number):\n",
    "    # Connect to an existing database\n",
    "conn = None\n",
    "try:\n",
    "    conn = psycopg2.connect(#database=\"public\",\n",
    "                        port = \"5432\",\n",
    "                        host=\"localhost\", \n",
    "                        user=\"postgres\", \n",
    "                        password=\"1234\")\n",
    "except psycopg2.DatabaseError as e: \n",
    "        print (f'Error {e}')\n",
    "        sys.exit(1)\n",
    "            \n",
    "    # Open a cursor to perform database operations\n",
    "cur = conn.cursor()\n",
    "\n",
    "    # Execute a command: this creates a new table\n",
    "\n",
    "cur.execute((\"\"\"SELECT article.type, article.content, url.sld\n",
    "from article \n",
    "inner join url \n",
    "on article.id = url.article_id \n",
    "and article.type IN ('fake','satire','bias','conspiracy','junksci','clickbait','political','reliable','state');\"\"\"))\n",
    "# cur.execute((\"\"\"SELECT article.type, article.content, author.name  \n",
    "# from article \n",
    "# inner join author \n",
    "# on article.id = author.id \n",
    "# and article.type IN ('fake','satire','bias','conspiracy','junksci','clickbait','political','reliable','state');\"\"\"))\n",
    "df = (cur.fetchmany(1000000))\n",
    "\n",
    "    # Make the changes to the database persistent\n",
    "conn.commit()\n",
    "\n",
    "    # Close communication with the database\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifier for multinomial models.\n",
    "\n",
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.\n",
    "\n",
    "Tager fra SKLearns hjemmeside :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pd.DataFrame(df, columns =[\"type\", \"content\", \"url\"])\n",
    "#df_articles = pd.DataFrame(df, columns =[\"type\", \"content\", \"author\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting our y variables into FAKE or REAL\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"hate\", \"FAKE\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"fake\", \"FAKE\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"unreliable\", \"FAKE\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"conspiracy\", \"FAKE\", df_articles[\"type\"])\n",
    "\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"satire\", \"FAKE\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"junksci\", \"FAKE\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"bias\", \"FAKE\", df_articles[\"type\"])\n",
    "\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"clickbait\", \"REAL\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"political\", \"REAL\", df_articles[\"type\"])\n",
    "\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"reliable\", \"REAL\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"state\", \"REAL\", df_articles[\"type\"])\n",
    "\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] != \"FAKE\", \"REAL\", df_articles[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_articles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "words = stopwords.words(\"english\")\n",
    "t1 = time.time()\n",
    "Data_transformed = df_articles['content'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "t2 = time.time()\n",
    "kage = t2-t1\n",
    "print(kage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a vectorized array with integers indicating frequency of words.\n",
    "vectorize = CountVectorizer(max_features=200,ngram_range=(1,3))\n",
    "x = vectorize.fit_transform(Data_transformed).toarray()\n",
    "y = np.array(df_articles['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a test split of 80/20.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=34)\n",
    "print('\\nTotal number of samples in the Train Dataset :',xtrain.shape[0])\n",
    "print('Total number of samples in the Test Dataset :',xtest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second baseline model using multinomial naive bayes.\n",
    "mulNB = MultinomialNB().fit(xtrain, ytrain)\n",
    "print('\\nAccuracy score for Multinomial Naive Bayes :',mulNB.score(xtest,ytest))\n",
    "\n",
    "ypred_mul = mulNB.predict(xtest)\n",
    "\n",
    "print('Confusion Metrics for Multinomial Naive Bayes : \\n\\n',confusion_matrix(ytest, ypred_mul),'\\n\\n')\n",
    "print('Classification Report for Multinomial Naive Bayes :\\n\\n',classification_report(ytest,ypred_mul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third baseline model using Logistic regression.\n",
    "scaler = StandardScaler()\n",
    "lr = LogisticRegression(max_iter = 600)\n",
    "log_model = Pipeline([('standardize', scaler),\n",
    "                    ('log_reg', lr)])\n",
    "\n",
    "log_model.fit(xtrain, ytrain)\n",
    "\n",
    "ypred_log = log_model.predict(xtest)\n",
    "test_accuracy = accuracy_score(ytest, ypred_log)*100\n",
    "\n",
    "print('Testing accuracy for Logistic regression: %.4f %%' % test_accuracy) \n",
    "print('Confusion Metrics for Logistic regression:\\n\\n', confusion_matrix(ytest, ypred_log))\n",
    "print('Classification Report for Multinomial Naive Bayes :\\n\\n',classification_report(ytest,ypred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slutTid = time.time()\n",
    "kage2 = slutTid-startTid\n",
    "print(kage2)\n",
    "print(\"Tid i min:\" ,kage2/60)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "425c1cb9f96b02dd326489ac6b96e3042bda6ec4abf5f4b3f4fc167f5a6a6fe0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
