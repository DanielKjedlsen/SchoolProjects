{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import psycopg2 as psycopg2\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTid = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to an existing database\n",
    "conn = None\n",
    "try:\n",
    "    conn = psycopg2.connect(#database=\"public\",\n",
    "                        port = \"5432\",\n",
    "                        host=\"localhost\", \n",
    "                        user=\"postgres\", \n",
    "                        password=\"1234\")\n",
    "except psycopg2.DatabaseError as e: \n",
    "        print (f'Error {e}')\n",
    "        sys.exit(1)\n",
    "            \n",
    "    # Open a cursor to perform database operations\n",
    "cur = conn.cursor()\n",
    "\n",
    "    # Execute a command: this creates a new table\n",
    "\n",
    "cur.execute((\"\"\"SELECT type, content FROM article WHERE type IN ('fake','satire','bias','conspiracy','junksci','clickbait','political','reliable','state') \"\"\")) #ORDER by random() LIMIT {};\"\"\".format(totalRow)))\n",
    "df = (cur.fetchmany(10000))\n",
    "\n",
    "    # Make the changes to the database persistent\n",
    "conn.commit()\n",
    "\n",
    "    # Close communication with the database\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = pd.DataFrame(df, columns =[\"type\", \"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting our y variables into FAKE or REAL\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"hate\", \"FAKE\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"fake\", \"FAKE\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"unreliable\", \"FAKE\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"conspiracy\", \"FAKE\", df_articles[\"type\"])\n",
    "\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"satire\", \"FAKE\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"junksci\", \"FAKE\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"bias\", \"FAKE\", df_articles[\"type\"])\n",
    "\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"clickbait\", \"REAL\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"political\", \"REAL\", df_articles[\"type\"])\n",
    "\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"reliable\", \"REAL\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"state\", \"REAL\", df_articles[\"type\"])\n",
    "\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] != \"FAKE\", \"REAL\", df_articles[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_articles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "words = stopwords.words(\"english\")\n",
    "Data_transformed = df_articles['article'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a vectorized array with integers indicating frequency of words.\n",
    "vectorize = CountVectorizer(max_features=200,ngram_range=(1,3))\n",
    "x = vectorize.fit_transform(Data_transformed).toarray()\n",
    "y = np.array(df_articles['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of samples in the Train Dataset : 8000\n",
      "Total number of samples in the Test Dataset : 2000\n"
     ]
    }
   ],
   "source": [
    "# Creating a test split of 80/20.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=34)\n",
    "print('\\nTotal number of samples in the Train Dataset :',xtrain.shape[0])\n",
    "print('Total number of samples in the Test Dataset :',xtest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy score for Multinomial Naive Bayes : 0.713\n",
      "Confusion Metrics for Multinomial Naive Bayes : \n",
      "\n",
      " [[465 197]\n",
      " [377 961]] \n",
      "\n",
      "\n",
      "Classification Report for Multinomial Naive Bayes :\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.55      0.70      0.62       662\n",
      "        REAL       0.83      0.72      0.77      1338\n",
      "\n",
      "    accuracy                           0.71      2000\n",
      "   macro avg       0.69      0.71      0.69      2000\n",
      "weighted avg       0.74      0.71      0.72      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Second baseline model using multinomial naive bayes.\n",
    "mulNB = MultinomialNB().fit(xtrain, ytrain)\n",
    "print('\\nAccuracy score for Multinomial Naive Bayes :',mulNB.score(xtest,ytest))\n",
    "\n",
    "ypred_mul = mulNB.predict(xtest)\n",
    "\n",
    "print('Confusion Metrics for Multinomial Naive Bayes : \\n\\n',confusion_matrix(ytest, ypred_mul),'\\n\\n')\n",
    "print('Classification Report for Multinomial Naive Bayes :\\n\\n',classification_report(ytest,ypred_mul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy for Logistic regression: 78.0000 %\n",
      "Confusion Metrics for Logistic regression:\n",
      "\n",
      " [[ 347  315]\n",
      " [ 125 1213]]\n",
      "Classification Report for Multinomial Naive Bayes :\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.74      0.52      0.61       662\n",
      "        REAL       0.79      0.91      0.85      1338\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.76      0.72      0.73      2000\n",
      "weighted avg       0.77      0.78      0.77      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Third baseline model using Logistic regression.\n",
    "scaler = StandardScaler()\n",
    "lr = LogisticRegression(max_iter = 600)\n",
    "log_model = Pipeline([('standardize', scaler),\n",
    "                    ('log_reg', lr)])\n",
    "\n",
    "log_model.fit(xtrain, ytrain)\n",
    "\n",
    "ypred_log = log_model.predict(xtest)\n",
    "test_accuracy = accuracy_score(ytest, ypred_log)*100\n",
    "\n",
    "print('Testing accuracy for Logistic regression: %.4f %%' % test_accuracy) \n",
    "print('Confusion Metrics for Logistic regression:\\n\\n', confusion_matrix(ytest, ypred_log))\n",
    "print('Classification Report for Multinomial Naive Bayes :\\n\\n',classification_report(ytest,ypred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "# clf2 = make_pipeline(StandardScaler(), SVC(C=1, gamma='auto', kernel='linear'))\n",
    "# clf2.fit(xtrain, ytrain)\n",
    "# predict2 = clf2.predict(xtest)\n",
    "\n",
    "# test_accuracy2 = accuracy_score(ytest, predict2)*100\n",
    "# print('Testing accuracy for SVM: %.4f %%' % test_accuracy2) \n",
    "# print('Testing accuracy for SVM: %.4f %%' % test_accuracy2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Har erstattet den ovenstående SVC model med denne, efter råd fra sklearns hjemmeside. \n",
    "from sklearn import svm\n",
    "\n",
    "clfsvm = svm.LinearSVC(max_iter=80000)\n",
    "clfsvm.fit(xtrain, ytrain)\n",
    "clfsvm.score(xtrain, ytrain)\n",
    "\n",
    "predicSVM = clfsvm.predict(xtest)\n",
    "clfsvm_acc = accuracy_score(ytest, predicSVM)*100\n",
    "\n",
    "print('Testing accuracy for svm: %.4f %%' % clfsvm_acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy for Forest: 84.1000 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf3 = RandomForestClassifier(max_depth=50, random_state=1)\n",
    "clf3.fit(xtrain, ytrain)\n",
    "\n",
    "predictForest = clf3.predict(xtest)\n",
    "test_accuracy3 = accuracy_score(ytest, predictForest)*100\n",
    "\n",
    "print('Testing accuracy for Forest: %.4f %%' % test_accuracy3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.676 total time=   3.0s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.680 total time=   3.1s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.678 total time=   3.1s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.679 total time=   3.3s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.674 total time=   3.1s\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.781 total time=   5.8s\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.761 total time=   4.7s\n",
      "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.759 total time=   5.1s\n",
      "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.758 total time=   4.2s\n",
      "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.768 total time=   5.0s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.675 total time=   2.6s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.677 total time=   2.6s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.675 total time=   2.7s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.677 total time=   2.5s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.670 total time=   2.5s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.781 total time=   5.3s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.761 total time=   4.3s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.759 total time=   4.6s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.758 total time=   4.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.768 total time=   4.9s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.702 total time=   3.0s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.708 total time=   2.9s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.699 total time=   2.9s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.698 total time=   2.9s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.699 total time=   2.9s\n",
      "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.786 total time=  35.0s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "param_grid = {'C': [0.1, 1],\n",
    "              'gamma': [1, 0.1],\n",
    "              'kernel': ['rbf', 'linear']}\n",
    " \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "# fitting the model for grid search\n",
    "grid.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'gamma': 1, 'kernel': 'linear'}\n",
      "SVC(C=1, gamma=1, kernel='linear')\n",
      "0.8150000000000001\n"
     ]
    }
   ],
   "source": [
    "print (grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.104356050491333\n",
      "Tid i min: 0.30173926750818886\n"
     ]
    }
   ],
   "source": [
    "slutTid = time.time()\n",
    "kage2 = slutTid-startTid\n",
    "print(kage2)\n",
    "print(\"Tid i min:\" ,kage2/60)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "425c1cb9f96b02dd326489ac6b96e3042bda6ec4abf5f4b3f4fc167f5a6a6fe0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
