{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and more "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import psycopg2 as psycopg2\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix \n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import time\n",
    "from tqdm.notebook import trange, tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retive Data for Test and Training. The data is put into two sets at present "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTid = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoint =250\n",
    "chunksize = 10\n",
    "totalRow = breakpoint * chunksize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def getDataSets(number):\n",
    "    # Connect to an existing database\n",
    "conn = None\n",
    "try:\n",
    "    conn = psycopg2.connect(#database=\"public\",\n",
    "                        port = \"5432\",\n",
    "                        host=\"localhost\", \n",
    "                        user=\"postgres\", \n",
    "                        password=\"1234\")\n",
    "except psycopg2.DatabaseError as e: \n",
    "        print (f'Error {e}')\n",
    "        sys.exit(1)\n",
    "            \n",
    "    # Open a cursor to perform database operations\n",
    "cur = conn.cursor()\n",
    "\n",
    "    # Execute a command: this creates a new table\n",
    "\n",
    "cur.execute((\"\"\"SELECT type, content FROM article WHERE type IN ('fake','satire','bias','conspiracy','junksci','clickbait','political','reliable','state') \"\"\")) #ORDER by random() LIMIT {};\"\"\".format(totalRow)))\n",
    "df = (cur.fetchmany(6))\n",
    "\n",
    "    # Make the changes to the database persistent\n",
    "conn.commit()\n",
    "\n",
    "    # Close communication with the database\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes classifier for multinomial models.\n",
    "\n",
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.\n",
    "\n",
    "Tager fra SKLearns hjemmeside :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split om noget af det sidste. Ellers vil det give problemmer snere når test og trænings sættene skal sammenlignes\n",
    "#train, test = train_test_split(pd.DataFrame(x, df), test_size = 0.20)\n",
    "#print (train.shape, test.shape\n",
    "\n",
    "df_articles = pd.DataFrame(df, columns =[\"type\", \"article\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting our y variables into FAKE or REAL\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"hate\", \"FAKE\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"fake\", \"FAKE\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"unreliable\", \"FAKE\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"conspiracy\", \"FAKE\", df_articles[\"type\"])\n",
    "\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"satire\", \"FAKE\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"junksci\", \"FAKE\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"bias\", \"FAKE\", df_articles[\"type\"])\n",
    "\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"clickbait\", \"REAL\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"political\", \"REAL\", df_articles[\"type\"])\n",
    "\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"reliable\", \"REAL\", df_articles[\"type\"])\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] == \"state\", \"REAL\", df_articles[\"type\"])\n",
    "\n",
    "df_articles[\"type\"] = np.where(df_articles[\"type\"] != \"FAKE\", \"REAL\", df_articles[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(718952, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_articles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2649.574954509735\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "words = stopwords.words(\"english\")\n",
    "t1 = time.time()\n",
    "Data_transformed = df_articles['article'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "t2 = time.time()\n",
    "kage = t2-t1\n",
    "print(kage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a vectorized array with integers indicating frequency of words.\n",
    "vectorize = CountVectorizer(max_features=200,ngram_range=(1,3))\n",
    "x = vectorize.fit_transform(Data_transformed).toarray()\n",
    "y = np.array(df_articles['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of samples in the Train Dataset : 575161\n",
      "Total number of samples in the Test Dataset : 143791\n"
     ]
    }
   ],
   "source": [
    "# Creating a test split of 80/20.\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=34)\n",
    "print('\\nTotal number of samples in the Train Dataset :',xtrain.shape[0])\n",
    "print('Total number of samples in the Test Dataset :',xtest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy score for Multinomial Naive Bayes : 0.7422648149049662\n",
      "Confusion Metrics for Multinomial Naive Bayes : \n",
      "\n",
      " [[64512 15982]\n",
      " [21078 42219]] \n",
      "\n",
      "\n",
      "Classification Report for Multinomial Naive Bayes :\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.75      0.80      0.78     80494\n",
      "        REAL       0.73      0.67      0.69     63297\n",
      "\n",
      "    accuracy                           0.74    143791\n",
      "   macro avg       0.74      0.73      0.74    143791\n",
      "weighted avg       0.74      0.74      0.74    143791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Second baseline model using multinomial naive bayes.\n",
    "mulNB = MultinomialNB().fit(xtrain, ytrain)\n",
    "print('\\nAccuracy score for Multinomial Naive Bayes :',mulNB.score(xtest,ytest))\n",
    "\n",
    "ypred_mul = mulNB.predict(xtest)\n",
    "\n",
    "print('Confusion Metrics for Multinomial Naive Bayes : \\n\\n',confusion_matrix(ytest, ypred_mul),'\\n\\n')\n",
    "print('Classification Report for Multinomial Naive Bayes :\\n\\n',classification_report(ytest,ypred_mul))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy for Logistic regression: 74.3148 %\n",
      "Confusion Metrics for Logistic regression:\n",
      "\n",
      " [[67394 13100]\n",
      " [23833 39464]]\n",
      "Classification Report for Multinomial Naive Bayes :\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.74      0.84      0.78     80494\n",
      "        REAL       0.75      0.62      0.68     63297\n",
      "\n",
      "    accuracy                           0.74    143791\n",
      "   macro avg       0.74      0.73      0.73    143791\n",
      "weighted avg       0.74      0.74      0.74    143791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Third baseline model using Logistic regression.\n",
    "scaler = StandardScaler()\n",
    "lr = LogisticRegression(max_iter = 600)\n",
    "log_model = Pipeline([('standardize', scaler),\n",
    "                    ('log_reg', lr)])\n",
    "\n",
    "log_model.fit(xtrain, ytrain)\n",
    "\n",
    "ypred_log = log_model.predict(xtest)\n",
    "test_accuracy = accuracy_score(ytest, ypred_log)*100\n",
    "\n",
    "print('Testing accuracy for Logistic regression: %.4f %%' % test_accuracy) \n",
    "print('Confusion Metrics for Logistic regression:\\n\\n', confusion_matrix(ytest, ypred_log))\n",
    "print('Classification Report for Multinomial Naive Bayes :\\n\\n',classification_report(ytest,ypred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5113.834833145142\n",
      "Tid i min: 85.23058055241903\n"
     ]
    }
   ],
   "source": [
    "slutTid = time.time()\n",
    "kage2 = slutTid-startTid\n",
    "print(kage2)\n",
    "print(\"Tid i min:\" ,kage2/60)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "425c1cb9f96b02dd326489ac6b96e3042bda6ec4abf5f4b3f4fc167f5a6a6fe0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
